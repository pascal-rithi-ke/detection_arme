import streamlit as st
import cv2
import numpy as np
import tempfile
import os

# Charger le mod√®le YOLO
net = cv2.dnn.readNet("dataset_yolo/yolov3.weights", "dataset_yolo/yolov3.cfg")

# Configurer les param√®tres d'entra√Ænement
net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)

# Charger les classes
classes = []
with open("dataset_yolo/classes.txt", "r") as f:
    classes = [line.strip() for line in f]

# D√©finir le titre et l'ic√¥ne de la page
st.set_page_config(
    page_title="Vid√©os - D√©tection d'armes",
    page_icon="üé•",
)

# Afficher le titre
st.write("# Vid√©os")

# Ajouter le composant d'upload de fichier
upload_video = st.file_uploader("Choisissez une vid√©o", type=["mp4", "avi", "mov"])

# Si un fichier a √©t√© upload√©
if upload_video is not None:
    # Enregistrer le fichier uploader dans un r√©pertoire temporaire
    temp_dir = tempfile.TemporaryDirectory()
    video_path = os.path.join(temp_dir.name, "uploaded_video.mp4")
    with open(video_path, "wb") as video_file:
        video_file.write(upload_video.read())

    # Lire la vid√©o √† l'aide d'OpenCV
    video_capture = cv2.VideoCapture(video_path)

    # D√©finir la taille de la fen√™tre de la vid√©o
    width = int(video_capture.get(3))
    height = int(video_capture.get(4))

    # Cr√©er un √©l√©ment Streamlit pour afficher la vid√©o
    video_placeholder = st.empty()

    # Lire la vid√©o frame par frame
    while video_capture.isOpened():
        ret, frame = video_capture.read()
        if not ret:
            break

        # Cr√©er un blob √† partir de l'image
        blob = cv2.dnn.blobFromImage(frame, 1/255, (416, 416), (0, 0, 0), True, crop=False)
        net.setInput(blob)

        layer_names = net.getUnconnectedOutLayersNames()
        detections = net.forward(layer_names)

        # Post-traitement des d√©tections
        for obj in detections[0]:
            scores = obj[5:]
            class_id = np.argmax(scores)
            confidence = scores[class_id]

            if confidence > 0.5:
                center_x = int(obj[0] * width)
                center_y = int(obj[1] * height)
                w = int(obj[2] * width)
                h = int(obj[3] * height)

                x = int(center_x - w/2)
                y = int(center_y - h/2)

                # Dessiner un rectangle autour de l'objet d√©tect√©
                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
                cv2.putText(frame, f"{classes[class_id]}: {confidence:.2f}", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        # Afficher la vid√©o dans Streamlit avec le rectangle superpos√©
        video_placeholder.image(frame, channels="BGR")

    # Lib√©rer la ressource vid√©o
    video_capture.release()
    # Supprimer le r√©pertoire temporaire
    temp_dir.cleanup()