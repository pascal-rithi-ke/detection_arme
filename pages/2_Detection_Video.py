import streamlit as st
import cv2
import numpy as np
import tempfile
import os
import time

# Charger le mod√®le YOLO
net = cv2.dnn.readNet("dataset_yolo/yolov3.weights", "dataset_yolo/yolov3.cfg")

# Configurer les param√®tres d'entra√Ænement
net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)

# Charger les classes
classes = []
with open("dataset_yolo/classes.txt", "r") as f:
    classes = [line.strip() for line in f]

# D√©finir les indices des classes pour Gun, Knife et Rifle
allowed_classes = ['Gun', 'Knife', 'Rifle']
allowed_class_ids = [classes.index(cls) for cls in allowed_classes]

# D√©finir le titre et l'ic√¥ne de la page
st.set_page_config(
    page_title="Vid√©os - D√©tection d'armes",
    page_icon="üé•",
)

# Afficher le titre
st.write("# Vid√©os")

# Ajouter le composant d'upload de fichier
upload_video = st.file_uploader("Choisissez une vid√©o", type=["mp4", "avi", "mov"])

# Si un fichier a √©t√© upload√©
if upload_video is not None:
    # Enregistrer le fichier uploader dans un r√©pertoire temporaire
    temp_dir = tempfile.TemporaryDirectory()
    video_path = os.path.join(temp_dir.name, "uploaded_video.mp4")
    with open(video_path, "wb") as video_file:
        video_file.write(upload_video.read())

    # Lire la vid√©o √† l'aide d'OpenCV
    video_capture = cv2.VideoCapture(video_path)

    # Obtenir les propri√©t√©s de la vid√©o
    width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = video_capture.get(cv2.CAP_PROP_FPS)  # Fr√©quence d'images de la vid√©o

    # Cr√©er un √©l√©ment Streamlit pour afficher la vid√©o
    video_placeholder = st.empty()

    # D√©finir le facteur de saut de frames
    frame_skip = st.slider("Sauter des frames pour acc√©l√©rer (1 = toutes les frames, 5 = une frame sur 5)", 1, 10, 3)

    frame_counter = 0  # Compteur pour savoir quelles frames afficher

    # Lire la vid√©o frame par frame
    while video_capture.isOpened():
        ret, frame = video_capture.read()
        if not ret:
            break

        # Ne traiter qu'une frame sur "frame_skip"
        if frame_counter % frame_skip == 0:
            # Cr√©er un blob √† partir de l'image
            blob = cv2.dnn.blobFromImage(frame, 1/255, (416, 416), (0, 0, 0), True, crop=False)
            net.setInput(blob)

            layer_names = net.getUnconnectedOutLayersNames()
            detections = net.forward(layer_names)

            # Post-traitement des d√©tections
            for detection in detections:
                for obj in detection:
                    scores = obj[5:]
                    class_id = np.argmax(scores)
                    confidence = scores[class_id]

                    # Filtrer les classes autoris√©es et les d√©tections avec confiance suffisante
                    if confidence > 0.65 and class_id in allowed_class_ids:
                        center_x = int(obj[0] * width)
                        center_y = int(obj[1] * height)
                        w = int(obj[2] * width)
                        h = int(obj[3] * height)

                        # Ajustement du padding autour de l'objet
                        padding = 0.1  # Ajuste ce facteur si n√©cessaire
                        w = int(w * (1 - padding))
                        h = int(h * (1 - padding))

                        x = int(center_x - w/2)
                        y = int(center_y - h/2)

                        # Dessiner un rectangle autour de l'objet d√©tect√©
                        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
                        cv2.putText(frame, f"{classes[class_id]}: {confidence:.2f}", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

            # Afficher la vid√©o dans Streamlit avec le rectangle superpos√©
            video_placeholder.image(frame, channels="BGR")

        # Incr√©menter le compteur de frames
        frame_counter += 1

    # Lib√©rer la ressource vid√©o
    video_capture.release()
    # Supprimer le r√©pertoire temporaire
    temp_dir.cleanup()
